{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ef9f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use RNA-STAR conda environment\n",
    "from pathlib import Path\n",
    "import traceback\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pysam\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a740903",
   "metadata": {},
   "source": [
    "### Opening BAM file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33b5bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pysam_pileup(bamfile, chrom, mod_base, base_ct):\n",
    "    \"\"\"\n",
    "    Counts number of bases/deletions in PileupColumn \n",
    "    for each GenomicModBase\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for pileupcolumn in bamfile.pileup(str(chrom), int(mod_base-1), int(mod_base), truncate = True): ## pysam is 0-based, while GenomicModBase was 1-based\n",
    "            pileupcolumn.set_min_base_quality(0) ## prevent pysam from filtering based on base quality\n",
    "            if pileupcolumn.pos == int(mod_base-1):\n",
    "                for pileupread in pileupcolumn.pileups:\n",
    "                    if pileupread.is_del and not pileupread.is_refskip:\n",
    "                        base_ct[\"Deletions\"] += 1\n",
    "                    elif not pileupread.is_refskip:\n",
    "                        base = pileupread.alignment.query_sequence[pileupread.query_position] ## taken from example in manual; returns base letter\n",
    "                        if base in base_ct:\n",
    "                            base_ct[base] += 1\n",
    "                        else:\n",
    "                            continue\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to count bases/deletions in PileupColumn for Chromosome {chrom} at GenomicModBase {mod_base}: {e}\")\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "def count_base(chunk, input_bam_name, results):\n",
    "    bamfile = pysam.AlignmentFile(input_bam_name, \"rb\")\n",
    "    \"\"\"\n",
    "    Counts number of bases/deletions for each UNUAR site\n",
    "        1) chrom: value in \"Chrom\" column (e.g., NW_018654708.1)\n",
    "        2) mod_base: value in \"GenomicModBase\" column (e.g., 373)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for row in chunk:\n",
    "            chrom = row[0]\n",
    "            mod_base = row[1]\n",
    "            base_ct = {\"A\": 0, \"C\": 0, \"G\": 0, \"T\": 0, \"Deletions\": 0}\n",
    "\n",
    "            pysam_pileup(bamfile, chrom, mod_base, base_ct)\n",
    "\n",
    "            results.append({\"Chrom\": chrom,\n",
    "                            \"GenomicModBase\": mod_base,\n",
    "                            **base_ct}) ## unpack base_ct dict in this dict\n",
    "        bamfile.close()\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to count bases/deletions in UNUAR sites: {e}\")\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "def process_chunk(genome_coord, input_bam_name, results):\n",
    "    try:\n",
    "        all_chunks = np.array_split(genome_coord, 100)\n",
    "        with concurrent.futures.ThreadPoolExecutor(max_workers = 12) as executor:\n",
    "            futures = [executor.submit(count_base, chunk, input_bam_name, results) for chunk in all_chunks]\n",
    "            for future in concurrent.futures.as_completed(futures):\n",
    "                future.result()\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parallelize chunks: {e}\")\n",
    "        traceback.print_exc()\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa95dd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## main code\n",
    "def open_bam(folder_name):\n",
    "    \"\"\"\n",
    "    Opens .bam in folder\n",
    "    and runs calculations\n",
    "    \"\"\"\n",
    "    current_path = Path.cwd()\n",
    "    input_dir = current_path/\"realignments\"/folder_name\n",
    "\n",
    "    left = pd.read_csv(f\"{current_path}/UNUAR_motif_sites_mRNA.tsv\", sep = \"\\t\")\n",
    "    left[\"Motif\"] = left[\"Motif\"].str.replace(\"U\", \"T\") ## each BAM file has sequences w/ Thymine (T) instead of Uracil (U)\n",
    "    right = pd.read_excel(f\"{current_path}/SupplementaryTable1.xlsx\")\n",
    "\n",
    "    df = pd.merge(left, right, how = \"left\", on = \"Motif\")\n",
    "    genome_coord = df[[\"Chrom\", \"GenomicModBase\"]].to_numpy() ## faster processing\n",
    "    \n",
    "    try: \n",
    "        for subfolder in input_dir.iterdir():\n",
    "            if subfolder.is_dir():\n",
    "                processed_folder = input_dir/f\"{subfolder.name}_realigned\"\n",
    "                \n",
    "                for bam in subfolder.glob(\"*.bam\"):\n",
    "                    results = []\n",
    "                    input_bam_name = Path(bam) ## turn string from list back into filepath\n",
    "                    output_tsv_name = processed_folder/f\"{input_bam_name.stem}.tsv\"\n",
    "                    \n",
    "                    ## count A, C, G, T and deletions @ each UNUAR site\n",
    "                    process_chunk(genome_coord, input_bam_name, results)\n",
    "\n",
    "                    ## calculate observed deletion rates\n",
    "                    counts = pd.DataFrame(results)\n",
    "                    sums = counts[[\"A\", \"C\", \"G\", \"T\", \"Deletions\"]].sum(axis = 1) ## sum across rows\n",
    "                    counts_filtered = counts[sums != 0] ## only keep rows where sum does not equal 0 (prevents division by 0)\n",
    "                    counts_filtered.loc[:, \"DeletionRate\"] = counts_filtered[\"Deletions\"]/counts_filtered[[\"A\", \"C\", \"G\", \"T\", \"Deletions\"]].sum(axis = 1)\n",
    "                    \n",
    "                    ## calculate real deletion rates\n",
    "                    df_final = pd.merge(df, counts_filtered, how = \"left\", on = [\"Chrom\", \"GenomicModBase\"])\n",
    "                    num = df_final[\"DeletionRate\"] - df_final[\"fit_B\"]\n",
    "                    denom = ((df_final[\"fit_R\"] - df_final[\"fit_B\"]) + \n",
    "                             df_final[\"fit_A\"]*(df_final[\"DeletionRate\"] - df_final[\"fit_R\"] - df_final[\"fit_B\"]))\n",
    "                    df_final[\"RealRate\"] = num/denom\n",
    "\n",
    "                    ## add all calculations to og dataframe & save as .tsv output\n",
    "                    df_final.to_csv(output_tsv_name, sep = \"\\t\", index = False)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to calculate observed & real deletion rates in {folder_name} and save as .tsv: {e}\")\n",
    "        traceback.print_exc()\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02112d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description = \"Calculates observed and real deletion rates for every UNUAR site in a BAM file.\")\n",
    "    parser.add_argument(\"--folder_name\", help = \"Name of processed_fastqs folder\", required = True)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    print(\"Calculating deletion rates...\")\n",
    "    open_bam(args.folder_name)\n",
    "    print(\"Process finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
