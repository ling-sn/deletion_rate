{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "028b3433",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use RNA-STAR conda environment\n",
    "from pathlib import Path\n",
    "import traceback\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from scipy.stats import fisher_exact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4b15cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_regex(folder_name):\n",
    "    \"\"\"\n",
    "    Given input folder names, extract the group name.\n",
    "        EXAMPLE: '7KO-Cyto-BS_processed_fastqs' -> '7KO-Cyto'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        match = re.match(r\"(.+)-(?:BS|NBS)_processed_fastqs\", folder_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to match input folder to group with RegEx: {e}\")\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "    return match.group(1) ## return first regex capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd90734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_columns(merged_colnames, fisher_colnames, df_merged):\n",
    "   \"\"\"\n",
    "   1. Takes all columns from merged df\n",
    "      and organizes them by BS/NBS type \n",
    "   2. Sums up corresponding bases and deletions\n",
    "      and creates new columns in df\n",
    "   \"\"\"\n",
    "   bs_base_pattern = re.compile(r\".+_(A|C|G|T)_BS$\")\n",
    "   nbs_base_pattern = re.compile(r\".+_(A|C|G|T)_NBS$\")\n",
    "   bs_del_pattern = re.compile(r\".+_(Deletions)_BS$\")\n",
    "   nbs_del_pattern = re.compile(r\".+_(Deletions)_NBS$\")\n",
    "    \n",
    "   pattern_dict = {\"Bases_BS\": [col for col in merged_colnames if bs_base_pattern.match(col)],\n",
    "                   \"Bases_NBS\": [col for col in merged_colnames if nbs_base_pattern.match(col)],\n",
    "                   \"Deletions_BS\": [col for col in merged_colnames if bs_del_pattern.match(col)],\n",
    "                   \"Deletions_NBS\": [col for col in merged_colnames if nbs_del_pattern.match(col)]}\n",
    "\n",
    "   try:\n",
    "      for newcol, key in zip(fisher_colnames, pattern_dict):\n",
    "         df_merged[newcol] = df_merged[pattern_dict[key]].sum(axis=1)\n",
    "         \n",
    "   except Exception as e:\n",
    "      print(f\"Failed to create new columns for Fisher's Exact Test: {e}\")\n",
    "      traceback.print_exc()\n",
    "      raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e30fb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterTSV:\n",
    "    def merged_output(df_merged):\n",
    "        \"\"\"\n",
    "        1. Creates 4 new columns\n",
    "        2. Selects new columns in df\n",
    "           * Reshapes each row into 2x2 matrix\n",
    "           * Runs Fisher's Exact Test\n",
    "           * Appends p-value column\n",
    "        \"\"\"\n",
    "        merged_colnames = df_merged.columns.tolist()\n",
    "        fisher_colnames = [\"TotalBases_BS\", \"TotalBases_NBS\", \"TotalDeletions_BS\", \"TotalDeletions_NBS\"]\n",
    "        create_columns(merged_colnames, fisher_colnames, df_merged) ## add 4 new columns\n",
    "        df_merged[\"p_value\"] = df_merged[fisher_colnames].apply(lambda row: fisher_exact(row.values.reshape(2, 2))[1], axis=1) ## each row is reshaped into 2x2 matrix\n",
    "        df_merged = df_merged.drop(columns=[\"index\"])\n",
    "    \n",
    "    def filtered_output():\n",
    "        text\n",
    "\n",
    "    def discarded_output():\n",
    "        text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe8a426",
   "metadata": {},
   "outputs": [],
   "source": [
    "## main code\n",
    "def clean_output(folder_name):\n",
    "    \"\"\"\n",
    "    Filters .tsv files in grouped folders\n",
    "    \"\"\"\n",
    "    current_path = Path.cwd()\n",
    "    group_name = match_regex(folder_name)\n",
    "    input_folder = current_path/\"calculations\"/group_name/\"individual_tsv\"\n",
    "    processed_folder = current_path/\"calculations\"/group_name\n",
    "\n",
    "    try: \n",
    "        if input_folder.is_dir():\n",
    "            tsv_list = [*input_folder.glob(\"*.tsv\")] ## collect paths of tsv files and put in a list            \n",
    "            num = [\"df%s\" %s for s in range(1,7)] ## creates a list of strings: df1, df2, ..., df6\n",
    "            listcomp = [pd.read_csv(i, sep = \"\\t\") for i in tsv_list] ## reads in all tsv files as pandas df; access 1st df w/ listcomp[0], etc.\n",
    "            df_dict = dict(zip(num, listcomp))\n",
    "\n",
    "            ## Merge pandas dataframes\n",
    "            colnames = df_dict[\"df1\"].columns.tolist()\n",
    "            selected_colnames = [\"index\"] + colnames[0:17] ## columns that are always the same throughout all dfs\n",
    "\n",
    "            for i in num:\n",
    "                if i=0:\n",
    "                    ## merge df1 + df2\n",
    "                    df_merged = pd.merge(df_dict[i].reset_index(), df_dict[i+1].reset_index(), on = selected_colnames, how = \"outer\")\n",
    "                elif i=5:\n",
    "                    break\n",
    "                else:\n",
    "                    ## for remaining dfs after df1 + df2, overwrite existing var: df_merged = df_merged + df_dict[i+1]\n",
    "                    df_merged = pd.merge(df_merged, df_dict[i+1].reset_index(), on = selected_colnames, how = \"outer\")\n",
    "\n",
    "            ## Initialize class\n",
    "            filtertsv = FilterTSV()\n",
    "\n",
    "            ## Save merged .tsv (all_sites)\n",
    "            filtertsv.merged_output(df_merged)\n",
    "            df_merged.to_csv(f\"{processed_folder}/{group_name}_all_sites.tsv\", sep = \"\\t\", index = False)\n",
    "\n",
    "            ## Save null .tsv (no_data)\n",
    "            null_rows = df_merged.isnull().any(axis=1)\n",
    "            df_null = df_merged[null_rows].copy()\n",
    "            df_null.to_csv(f\"{processed_folder}/{group_name}_no_data.tsv\", sep = \"\\t\", index = False)\n",
    "\n",
    "            ## Save filtered .tsv (priority_filtered)\n",
    "\n",
    "            ## Save discarded .tsv (non_sites)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create merged .tsv file: {e}\")\n",
    "        traceback.print_exc()\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7062ddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description = \"Filters .tsv outputs from calculate_dr script.\")\n",
    "    parser.add_argument(\"--folder_name\", help = \"Name of processed_fastqs folder\", required = True)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    print(\"Filtering .tsv files...\")\n",
    "    clean_output(args.folder_name)\n",
    "    print(\"Process finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e44f50d",
   "metadata": {},
   "source": [
    "### Extra code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed9fce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional mean\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "col = \"my_column\"\n",
    "threshold = 10\n",
    "\n",
    "filtered = df[df[col] > threshold]\n",
    "\n",
    "if filtered[col].mean() > threshold:\n",
    "    df = filtered\n",
    "else:\n",
    "    # If you want, keep original df or do something else\n",
    "    pass\n",
    "\n",
    "###################\n",
    "\n",
    "## Fisher's Exact Tests\n",
    "from scipy.stats import fisher_exact\n",
    "\n",
    "# df with columns: 'A', 'B', 'C', 'D'\n",
    "def get_pvalue(row):\n",
    "    table = [[row['A'], row['B']], [row['C'], row['D']]]\n",
    "    _, p = fisher_exact(table)\n",
    "    return p\n",
    "\n",
    "df['p_value'] = df.apply(get_pvalue, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
